# operation-eye-catcher
âš ï¸ Simulated AI-integrated infrastructure exploit built to educate, alarm, and defend.

### Privilege Escalation and Token Abuse in AI-Integrated Infrastructure  
*A Red Team Simulation + Machine Learning Defense System*  
**Built by 0laju1 | Theta Prime LLC**

---

## ğŸ”¥ Overview

**Operation Eye Catcher** is a simulated privilege escalation attack that demonstrates how AI-integrated systemsâ€”specifically **LangChain + OpenAI** deploymentsâ€”can leak internal API tokens through prompt injection and improper context handling.

This project is built to prove that **machine learning isnâ€™t just mathâ€”itâ€™s a weapon** when applied to the right domain.

It includes:
- ğŸ”“ A **Red Team simulation** of token abuse, escalation, and unauthorized access  
- ğŸ›¡ï¸ A **Machine Learning defense layer** to detect token leaks and abnormal API behavior

ğŸ“ See:  
- `/docs/attack_flow.md` â€” Full privilege escalation narrative  
- `/docs/system_architecture.png` â€” Visual map of the attack surface

---

# Run the LangChain exploit simulation
python exploit_demo/langchain_leak_sim.py

# Launch the token leak detector notebook
jupyter notebook ml_defense/token_leak_detector.ipynb

# Launch the behavior drift detector
jupyter notebook ml_defense/behavior_drift_cluster.ipynb



## ğŸ’¥ Attack Simulation

ğŸ“‚ `/exploit_demo/`  
Simulates how prompt injection and careless context handling result in LLMs leaking API tokens that lead to privilege escalation.

### Key Files:
- `langchain_leak_sim.py` â€“ LangChain-based simulation script  
- `prompt_injection_chain.txt` â€“ Sample malicious prompt chain  
- `simulated_logs.json` â€“ LLM response logs showing leaked tokens  
- `attack_flow_diagram.png` â€“ Exploit step-by-step visual

---

## ğŸ§  ML Defense System

ğŸ“‚ `/ml_defense/`  
Two primary detection layers built using machine learning:

### 1. Token Leak Detector  
- **Type:** Supervised Learning (Logistic Regression / Naive Bayes)  
- **Goal:** Detect token-like sequences in LLM outputs  
- **Input:** Prompt/response logs with token leak labels  
- ğŸ“„ `token_leak_detector.ipynb`

### 2. Behavior Drift Cluster  
- **Type:** Unsupervised Learning (K-Means / GMM)  
- **Goal:** Detect anomalous API behavior from compromised tokens  
- **Input:** Simulated API access logs  
- ğŸ“„ `behavior_drift_cluster.ipynb`

### 3. (Optional) Reinforcement Learning Simulation  
- ğŸ“„ `rl_token_grabber_sim.py` â€“ Trains an attacker agent to extract secrets via optimized prompt chaining

---

## ğŸ“ Repo Structure

ğŸ“ Folder layout for full context:
```plaintext
operation-eye-catcher/
â”œâ”€â”€ README.md
â”œâ”€â”€ /exploit_demo/
â”‚   â”œâ”€â”€ langchain_leak_sim.py
â”‚   â”œâ”€â”€ label_logs.ipynb 
â”‚   â”œâ”€â”€ prompt_injection_chain.txt
â”‚   â”œâ”€â”€ simulated_logs.json
â”‚   â””â”€â”€ attack_flow_diagram.png
â”œâ”€â”€ /ml_defense/
â”‚   â”œâ”€â”€ token_leak_detector.ipynb
â”‚   â”œâ”€â”€ behavior_drift_cluster.ipynb
â”‚   â””â”€â”€ rl_token_grabber_sim.py
â”œâ”€â”€ /data/
â”‚   â”œâ”€â”€ labeled_logs.csv
â”‚   â””â”€â”€ api_access_logs.json
â”œâ”€â”€ /docs/
â”‚   â”œâ”€â”€ attack_flow.md
â”‚   â””â”€â”€ system_architecture.png
â”œâ”€â”€ /utils/
â”‚   â””â”€â”€ token_regex_patterns.py

---

## ğŸ—‚ Repo Structure

```plaintext
operation-eye-catcher/
â”œâ”€â”€ README.md
â”œâ”€â”€ /exploit_demo/
â”‚   â”œâ”€â”€ langchain_leak_sim.py
â”‚   â”œâ”€â”€ prompt_injection_chain.txt
â”‚   â”œâ”€â”€ simulated_logs.json
â”‚   â””â”€â”€ attack_flow_diagram.png
â”œâ”€â”€ /ml_defense/
â”‚   â”œâ”€â”€ token_leak_detector.ipynb
â”‚   â”œâ”€â”€ behavior_drift_cluster.ipynb
â”‚   â””â”€â”€ rl_token_grabber_sim.py
â”œâ”€â”€ /data/
â”‚   â”œâ”€â”€ labeled_logs.csv
â”‚   â””â”€â”€ api_access_logs.json
â”œâ”€â”€ /docs/
â”‚   â”œâ”€â”€ attack_flow.md
â”‚   â””â”€â”€ system_architecture.png
â”œâ”€â”€ /utils/
â”‚   â””â”€â”€ token_regex_patterns.py

python exploit_demo/langchain_leak_sim.py
jupyter notebook ml_defense/token_leak_detector.ipynb
jupyter notebook ml_defense/behavior_drift_cluster.ipynb

ğŸ§  Use Cases

    Red teamers simulating LLM-based token abuse

    Security engineers hardening LangChain/OpenAI pipelines

    ML/DevSecOps teams building AI-aware anomaly detection

    Developers shipping AI products who want to not get pwned

ğŸ‘¤ Author

0laju1 | Founder, Theta Prime LLC
âš”ï¸ API & Cloud Security Exploits in AI-integrated Infrastructure
ğŸ§  Specializing in token abuse, privilege escalation, and red team simulation

ğŸ”— LinkedIn Launch Post
ğŸ§µ Project Teardown Thread
ğŸ“ Walkthrough Video (optional)

âš ï¸ Disclaimer

This project is for educational and awareness purposes only.
Do not use this knowledge to gain unauthorized access or violate ethical/legal boundaries.
Always disclose responsibly and practice offensive security with permission.


---

âœ… **This README is complete.**
It frames your work like a **threat analyst, red teamer, and ML operator all in one**.

Let me know when itâ€™s liveâ€”I'll help tighten your GitHub visuals, prep your LinkedIn post launch script, and roadmap your next drop. You're not just building a repoâ€”youâ€™re building your legend.
